{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33cdd22",
   "metadata": {},
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48d2de54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bea8f474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hectares</th>\n",
       "      <th>Agriblock</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Soil Types</th>\n",
       "      <th>Seedrate(in Kg)</th>\n",
       "      <th>LP_Mainfield(in Tonnes)</th>\n",
       "      <th>Nursery</th>\n",
       "      <th>Nursery area (Cents)</th>\n",
       "      <th>LP_nurseryarea(in Tonnes)</th>\n",
       "      <th>DAP_20days</th>\n",
       "      <th>...</th>\n",
       "      <th>Wind Direction_D1_D30</th>\n",
       "      <th>Wind Direction_D31_D60</th>\n",
       "      <th>Wind Direction_D61_D90</th>\n",
       "      <th>Wind Direction_D91_D120</th>\n",
       "      <th>Relative Humidity_D1_D30</th>\n",
       "      <th>Relative Humidity_D31_D60</th>\n",
       "      <th>Relative Humidity_D61_D90</th>\n",
       "      <th>Relative Humidity_D91_D120</th>\n",
       "      <th>Trash(in bundles)</th>\n",
       "      <th>Paddy yield(in Kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>Cuddalore</td>\n",
       "      <td>CO_43</td>\n",
       "      <td>alluvial</td>\n",
       "      <td>150</td>\n",
       "      <td>75.0</td>\n",
       "      <td>dry</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>SW</td>\n",
       "      <td>W</td>\n",
       "      <td>NNW</td>\n",
       "      <td>WSW</td>\n",
       "      <td>72.0</td>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "      <td>85</td>\n",
       "      <td>540</td>\n",
       "      <td>35028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>Kurinjipadi</td>\n",
       "      <td>ponmani</td>\n",
       "      <td>clay</td>\n",
       "      <td>150</td>\n",
       "      <td>75.0</td>\n",
       "      <td>wet</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>NW</td>\n",
       "      <td>S</td>\n",
       "      <td>SE</td>\n",
       "      <td>SSE</td>\n",
       "      <td>64.6</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>87</td>\n",
       "      <td>600</td>\n",
       "      <td>35412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Panruti</td>\n",
       "      <td>delux ponni</td>\n",
       "      <td>alluvial</td>\n",
       "      <td>150</td>\n",
       "      <td>75.0</td>\n",
       "      <td>dry</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>ENE</td>\n",
       "      <td>NE</td>\n",
       "      <td>NNE</td>\n",
       "      <td>W</td>\n",
       "      <td>85.0</td>\n",
       "      <td>96</td>\n",
       "      <td>84</td>\n",
       "      <td>79</td>\n",
       "      <td>600</td>\n",
       "      <td>36300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Kallakurichi</td>\n",
       "      <td>CO_43</td>\n",
       "      <td>clay</td>\n",
       "      <td>150</td>\n",
       "      <td>75.0</td>\n",
       "      <td>wet</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>W</td>\n",
       "      <td>WNW</td>\n",
       "      <td>SE</td>\n",
       "      <td>S</td>\n",
       "      <td>88.5</td>\n",
       "      <td>95</td>\n",
       "      <td>81</td>\n",
       "      <td>84</td>\n",
       "      <td>540</td>\n",
       "      <td>35016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Sankarapuram</td>\n",
       "      <td>ponmani</td>\n",
       "      <td>alluvial</td>\n",
       "      <td>150</td>\n",
       "      <td>75.0</td>\n",
       "      <td>dry</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>240</td>\n",
       "      <td>...</td>\n",
       "      <td>SSE</td>\n",
       "      <td>W</td>\n",
       "      <td>SW</td>\n",
       "      <td>NW</td>\n",
       "      <td>72.7</td>\n",
       "      <td>91</td>\n",
       "      <td>83</td>\n",
       "      <td>81</td>\n",
       "      <td>600</td>\n",
       "      <td>34044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hectares     Agriblock      Variety Soil Types  Seedrate(in Kg)  \\\n",
       "0         6     Cuddalore        CO_43   alluvial              150   \n",
       "1         6   Kurinjipadi      ponmani       clay              150   \n",
       "2         6       Panruti  delux ponni   alluvial              150   \n",
       "3         6  Kallakurichi        CO_43       clay              150   \n",
       "4         6  Sankarapuram      ponmani   alluvial              150   \n",
       "\n",
       "   LP_Mainfield(in Tonnes) Nursery  Nursery area (Cents)  \\\n",
       "0                     75.0     dry                   120   \n",
       "1                     75.0     wet                   120   \n",
       "2                     75.0     dry                   120   \n",
       "3                     75.0     wet                   120   \n",
       "4                     75.0     dry                   120   \n",
       "\n",
       "   LP_nurseryarea(in Tonnes)  DAP_20days  ...  Wind Direction_D1_D30  \\\n",
       "0                          6         240  ...                     SW   \n",
       "1                          6         240  ...                     NW   \n",
       "2                          6         240  ...                    ENE   \n",
       "3                          6         240  ...                      W   \n",
       "4                          6         240  ...                    SSE   \n",
       "\n",
       "   Wind Direction_D31_D60  Wind Direction_D61_D90  Wind Direction_D91_D120  \\\n",
       "0                       W                     NNW                      WSW   \n",
       "1                       S                      SE                      SSE   \n",
       "2                      NE                     NNE                        W   \n",
       "3                     WNW                      SE                        S   \n",
       "4                       W                      SW                       NW   \n",
       "\n",
       "   Relative Humidity_D1_D30  Relative Humidity_D31_D60  \\\n",
       "0                      72.0                         78   \n",
       "1                      64.6                         85   \n",
       "2                      85.0                         96   \n",
       "3                      88.5                         95   \n",
       "4                      72.7                         91   \n",
       "\n",
       "   Relative Humidity_D61_D90  Relative Humidity_D91_D120  Trash(in bundles)  \\\n",
       "0                         88                          85                540   \n",
       "1                         84                          87                600   \n",
       "2                         84                          79                600   \n",
       "3                         81                          84                540   \n",
       "4                         83                          81                600   \n",
       "\n",
       "   Paddy yield(in Kg)  \n",
       "0               35028  \n",
       "1               35412  \n",
       "2               36300  \n",
       "3               35016  \n",
       "4               34044  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('paddyclean.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c3491b",
   "metadata": {},
   "source": [
    "I'm going to include an additional train test split for the time being since many of the functions don't work without two parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eeb63341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure column names are stripped of whitespace\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "X = data.drop(\"Paddy yield(in Kg)\", axis=1)\n",
    "y = data[\"Paddy yield(in Kg)\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad9dd99",
   "metadata": {},
   "source": [
    "**Ridge Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28deda16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56b1f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b95e5",
   "metadata": {},
   "source": [
    "I chose to use ridge regression due to a lack of confidence in whether some variables are relevant or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f471a88",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Sankarapuram'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m/var/folders/d7/g8wkwqjn04b5wd6db1c0_t740000gn/T/ipykernel_98010/3468480231.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m pipeline = Pipeline([\n\u001b[32m      4\u001b[39m     (\u001b[33m'scaler'\u001b[39m, StandardScaler()),\n\u001b[32m      5\u001b[39m     (\u001b[33m'ridge'\u001b[39m, Ridge())\n\u001b[32m      6\u001b[39m ])\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m pipeline.fit(X_train, y_train)\n",
      "\u001b[32m~/Desktop/datascience/ML2/Analytics2-Final/aidan/lib/python3.11/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~/Desktop/datascience/ML2/Analytics2-Final/aidan/lib/python3.11/site-packages/sklearn/pipeline.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    651\u001b[39m                 \u001b[33m\"`sklearn.set_config(enable_metadata_routing=True)`.\"\u001b[39m\n\u001b[32m    652\u001b[39m             )\n\u001b[32m    653\u001b[39m \n\u001b[32m    654\u001b[39m         routed_params = self._check_method_params(method=\u001b[33m\"fit\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m         Xt = self._fit(X, y, routed_params, raw_params=params)\n\u001b[32m    656\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"Pipeline\"\u001b[39m, self._log_message(len(self.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    657\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m self._final_estimator != \u001b[33m\"passthrough\"\u001b[39m:\n\u001b[32m    658\u001b[39m                 last_step_params = self._get_metadata_for_step(\n",
      "\u001b[32m~/Desktop/datascience/ML2/Analytics2-Final/aidan/lib/python3.11/site-packages/sklearn/pipeline.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    585\u001b[39m                 step_params=routed_params[name],\n\u001b[32m    586\u001b[39m                 all_params=raw_params,\n\u001b[32m    587\u001b[39m             )\n\u001b[32m    588\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[32m    590\u001b[39m                 cloned_transformer,\n\u001b[32m    591\u001b[39m                 X,\n\u001b[32m    592\u001b[39m                 y,\n",
      "\u001b[32m~/Desktop/datascience/ML2/Analytics2-Final/aidan/lib/python3.11/site-packages/joblib/memory.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __call__(self, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.func(*args, **kwargs)\n",
      "\u001b[32m~/Desktop/datascience/ML2/Analytics2-Final/aidan/lib/python3.11/site-packages/sklearn/pipeline.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1536\u001b[39m     \"\"\"\n\u001b[32m   1537\u001b[39m     params = params \u001b[38;5;28;01mor\u001b[39;00m {}\n\u001b[32m   1538\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m hasattr(transformer, \u001b[33m\"fit_transform\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m             res = transformer.fit_transform(X, y, **params.get(\u001b[33m\"fit_transform\"\u001b[39m, {}))\n\u001b[32m   1541\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m             res = transformer.fit(X, y, **params.get(\"fit\", {})).transform(\n\u001b[32m   1543\u001b[39m                 X, **params.get(\u001b[33m\"transform\"\u001b[39m, {})\n",
      "\u001b[32m~/Desktop/datascience/ML2/Analytics2-Final/aidan/lib/python3.11/site-packages/sklearn/utils/_set_output.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m     @wraps(f)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(self, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data_to_wrap, tuple):\n\u001b[32m    318\u001b[39m             \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m             return_tuple = (\n",
      "\u001b[32m~/Desktop/datascience/ML2/Analytics2-Final/aidan/lib/python3.11/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    893\u001b[39m             \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m    894\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, **fit_params).transform(X)\n\u001b[32m    895\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m             \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[32m~/Desktop/datascience/ML2/Analytics2-Final/aidan/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    903\u001b[39m             Fitted scaler.\n\u001b[32m    904\u001b[39m         \"\"\"\n\u001b[32m    905\u001b[39m         \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    906\u001b[39m         self._reset()\n\u001b[32m--> \u001b[39m\u001b[32m907\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.partial_fit(X, y, sample_weight)\n",
      "\u001b[32m~/Desktop/datascience/ML2/Analytics2-Final/aidan/lib/python3.11/site-packages/sklearn/base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~/Desktop/datascience/ML2/Analytics2-Final/aidan/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    939\u001b[39m         self : object\n\u001b[32m    940\u001b[39m             Fitted scaler.\n\u001b[32m    941\u001b[39m         \"\"\"\n\u001b[32m    942\u001b[39m         first_call = \u001b[38;5;28;01mnot\u001b[39;00m hasattr(self, \u001b[33m\"n_samples_seen_\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m         X = validate_data(\n\u001b[32m    944\u001b[39m             self,\n\u001b[32m    945\u001b[39m             X,\n\u001b[32m    946\u001b[39m             accept_sparse=(\u001b[33m\"csr\"\u001b[39m, \u001b[33m\"csc\"\u001b[39m),\n",
      "\u001b[32m~/Desktop/datascience/ML2/Analytics2-Final/aidan/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2950\u001b[39m             out = y\n\u001b[32m   2951\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2952\u001b[39m             out = X, y\n\u001b[32m   2953\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2955\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2957\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m~/Desktop/datascience/ML2/Analytics2-Final/aidan/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) from complex_warning\n",
      "\u001b[32m~/Desktop/datascience/ML2/Analytics2-Final/aidan/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m~/Desktop/datascience/ML2/Analytics2-Final/aidan/lib/python3.11/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2167\u001b[39m             )\n\u001b[32m   2168\u001b[39m         values = self._values\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2172\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2173\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2174\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Sankarapuram'"
     ]
    }
   ],
   "source": [
    "alpha_values = [0.1, 1.0, 10.0, 100.0]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge())\n",
    "])\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c7fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'ridge__alpha': alpha_values}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054e9bd",
   "metadata": {},
   "source": [
    "**Support Vector Machine (support vector regression)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf2aa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svr', SVR(C=1.0, epsilon=0.1))\n",
    "])\n",
    "pipeline.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aidan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
